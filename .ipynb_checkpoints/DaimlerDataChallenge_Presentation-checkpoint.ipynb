{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import string, re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "\n",
    "# nltk.download('punkt') # if needed\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49159, 3)\n",
      "13.256021409455842\n"
     ]
    }
   ],
   "source": [
    "#Loading the data\n",
    "train = pd.read_csv('Data\\\\train_E6oV3lV.csv',\n",
    "                   sep = ',',\n",
    "                   header = 0)\n",
    "\n",
    "toTrain = pd.read_csv('Data\\\\test_tweets_anuFYb8.csv',\n",
    "                   sep = ',',\n",
    "                   header = 0)\n",
    "\n",
    "toTrain['label'] = None\n",
    "\n",
    "wholeData = pd.concat([train, toTrain], ignore_index=True, sort = True)\n",
    "print(wholeData.shape)\n",
    "\n",
    "\n",
    "# check data integrity\n",
    "labels = wholeData['label'].values\n",
    "labelCount = train['label'].value_counts()\n",
    "balance = labelCount[0] / labelCount[1]\n",
    "print(balance) # Require some balancing in the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating samples\n",
    "indexTrain = list(range(train.shape[0]))\n",
    "indexToTrain = np.sort(np.array(list((set(wholeData.index.values) - set(indexTrain)))))\n",
    "\n",
    "sampleTrain = np.random.choice(indexTrain, size=int(float(len(indexTrain)) * 0.7), replace = False)\n",
    "sampleTest =  np.sort(np.array(list((set(indexTrain) - set(sampleTrain)))))\n",
    "\n",
    "reduced = np.random.choice(np.array(list(set(train[\"id\"][(labels[indexTrain] == 0)].index.values) - set(sampleTest))), sum(labels[sampleTrain] == 1))\n",
    "sampleTrainBal = np.append(reduced, np.array(list(set(train[\"id\"][(labels[indexTrain] == 1)].index.values) - set(sampleTest))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functionality functions\n",
    "\n",
    "# Use a classifier to predict, dispay performances and return f1 score.\n",
    "def predict_and_score(cls, data, lbs, name = None, ids = None, silent = False):\n",
    "    pred = cls.predict(data)\n",
    "\n",
    "    lbs = lbs.astype(int)\n",
    "    # print(cls.score(data, lbs))\n",
    "    \n",
    "    f1_score = sklearn.metrics.f1_score(lbs, pred)\n",
    "    if not silent:\n",
    "        print(sklearn.metrics.f1_score(lbs, pred))\n",
    "        print(sklearn.metrics.confusion_matrix(lbs, pred))\n",
    "        print(sklearn.metrics.classification_report(lbs, pred))\n",
    "    return f1_score\n",
    "\n",
    "# Use a classifier to predict and write prediction in a file.\n",
    "def predict_and_save(cls, data, name, ids = None):\n",
    "    pred = cls.predict(data)\n",
    "    df = pd.DataFrame({'id': ids, 'label': pred})\n",
    "    df.to_csv(name, sep = ',', index = False)\n",
    "    return(\"File {0} saved.\".format(name))\n",
    "\n",
    "\n",
    "# stem words in a setence\n",
    "def cleanSentence(s, stops):\n",
    "    st = LancasterStemmer()\n",
    "    lem = WordNetLemmatizer()\n",
    "    words = []\n",
    "    for w in word_tokenize(s):\n",
    "        if (w not in stops):\n",
    "            #words.append(st.stem(w))\n",
    "            words.append(lem.lemmatize(w))\n",
    "    return(\" \".join(words))\n",
    "\n",
    "#extract emtion from a sentence based on the given lexicon\n",
    "def extractEmotion(s, lex):\n",
    "    inter = set(s.split()).intersection(lex.index)\n",
    "    return lex.loc[inter, :].mean(axis = 0)\n",
    "\n",
    "# 2 rounds model\n",
    "def predict_ambiguous(cls1, cls2, data, data2= None, group = 1):\n",
    "    pred1 = cls1.predict(data)\n",
    "    if data2 is None:\n",
    "        pred2 = cls2.predict(data[pred1 == group])\n",
    "    else:\n",
    "        pred2 = cls2.predict(data2[pred1 == group])\n",
    "    pred1[pred1 == group] = pred2\n",
    "    return pred1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, I will try to keep the code cells independent.\n",
    "Please run the cells above if you have not. They prepare the data to be used in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "0.6425263157894737\n",
      "[[20761    46]\n",
      " [  803   763]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98     20807\n",
      "          1       0.94      0.49      0.64      1566\n",
      "\n",
      "avg / total       0.96      0.96      0.96     22373\n",
      "\n",
      "Test data\n",
      "0.49442379182156143\n",
      "[[8779  134]\n",
      " [ 410  266]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97      8913\n",
      "          1       0.67      0.39      0.49       676\n",
      "\n",
      "avg / total       0.93      0.94      0.94      9589\n",
      "\n",
      "Training new data\n",
      "Train data\n",
      "0.9656476520642926\n",
      "[[1491   75]\n",
      " [  34 1532]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.95      0.96      1566\n",
      "          1       0.95      0.98      0.97      1566\n",
      "\n",
      "avg / total       0.97      0.97      0.97      3132\n",
      "\n",
      "Test data\n",
      "0.42573913043478256\n",
      "[[7326 1587]\n",
      " [  64  612]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.82      0.90      8913\n",
      "          1       0.28      0.91      0.43       676\n",
      "\n",
      "avg / total       0.94      0.83      0.87      9589\n",
      "\n",
      "Training new data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'File NB1_balanced.csv saved.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First rough approach\n",
    "data1 = wholeData.copy()\n",
    "\n",
    "# Data cleaning\n",
    "# punctRE = re.compile(\"[a-zA-Z]+\" \" \")\n",
    "#data1[\"tweet\"] = data1[\"tweet\"].apply(lambda x: \"\".join(re.findall(punctRE, x)))\n",
    "\n",
    "data1[\"tweet\"] = data1[\"tweet\"].apply(lambda x: re.sub(\"@[\\w]*|[^a-zA-Z ]+\", '', x))\n",
    "\n",
    "# vectorise and classify\n",
    "vectoriser = CountVectorizer()\n",
    "data1V = vectoriser.fit_transform(data1[\"tweet\"])\n",
    "\n",
    "# umbalanced\n",
    "classifier1 = MultinomialNB()\n",
    "classifier1.fit(data1V[sampleTrain], labels[sampleTrain].astype(int))\n",
    "\n",
    "print('Train data')\n",
    "predict_and_score(classifier1, data1V[sampleTrain],  labels[sampleTrain])\n",
    "print('Test data')\n",
    "predict_and_score(classifier1, data1V[sampleTest], labels[sampleTest])\n",
    "\n",
    "print('Training new data')\n",
    "predict_and_save(classifier1, data1V[indexToTrain], \"NB1_umbalanced.csv\", wholeData.iloc[indexToTrain,:]['id'])\n",
    "\n",
    "\n",
    "# balanced\n",
    "classifier1 = MultinomialNB()\n",
    "classifier1.fit(data1V[sampleTrainBal], labels[sampleTrainBal].astype(int))\n",
    "\n",
    "print('Train data')\n",
    "predict_and_score(classifier1, data1V[sampleTrainBal],  labels[sampleTrainBal])\n",
    "print('Test data')\n",
    "predict_and_score(classifier1, data1V[sampleTest], labels[sampleTest])\n",
    "\n",
    "classifier1.fit(data1V[sampleTrainBal], labels[sampleTrainBal].astype(int))\n",
    "print('Training new data')\n",
    "predict_and_save(classifier1, data1V[indexToTrain], \"NB1_balanced.csv\", wholeData.iloc[indexToTrain,:]['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to improve the current model by taking advantage text specific functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = wholeData.copy()\n",
    "\n",
    "## removing @mentions and punctuation\n",
    "data2[\"tweet\"] = data2[\"tweet\"].apply(lambda x: re.sub(\"@[\\w]*|[^a-zA-Z ]+\", '', x))\n",
    "\n",
    "#print(data[\"tweet\"])\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data2[\"tweet\"] = data2[\"tweet\"].apply(lambda x: cleanSentence(x, stop_words))\n",
    "##/!\\ stemming might be a bit long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Train data\n",
      "0.9686700767263429\n",
      "[[1519   47]\n",
      " [  51 1515]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97      1566\n",
      "          1       0.97      0.97      0.97      1566\n",
      "\n",
      "avg / total       0.97      0.97      0.97      3132\n",
      "\n",
      "Test data\n",
      "0.4561270801815431\n",
      "[[7548 1365]\n",
      " [  73  603]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.85      0.91      8913\n",
      "          1       0.31      0.89      0.46       676\n",
      "\n",
      "avg / total       0.94      0.85      0.88      9589\n",
      "\n",
      "Training new data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'File NB_stem_balanced.csv saved.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# vectorise and classify\n",
    "vectoriser = CountVectorizer()\n",
    "data2V = vectoriser.fit_transform(data2[\"tweet\"])\n",
    "# balanced\n",
    "classifier2 = MultinomialNB()\n",
    "classifier2.fit(data2V[sampleTrainBal], labels[sampleTrainBal].astype(int))\n",
    "\n",
    "# check data integrity\n",
    "labelCount = wholeData['label'][sampleTrainBal].value_counts()\n",
    "balance = labelCount[0] / labelCount[1]\n",
    "print(balance)\n",
    "\n",
    "print('Train data')\n",
    "predict_and_score(classifier2, data2V[sampleTrainBal],  labels[sampleTrainBal])\n",
    "print('Test data')\n",
    "predict_and_score(classifier2, data2V[sampleTest], labels[sampleTest])\n",
    "\n",
    "print('Training new data')\n",
    "predict_and_save(classifier2, data2V[indexToTrain], \"NB_stem_balanced.csv\", wholeData.iloc[indexToTrain,:]['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To overcome the overfitting, the sampling can be adjusted:\n",
    "# Because the data is unbalanced, the proportion classes play a large role.\n",
    "# \"Cross validation type of approach\" can help determine the best proportion to use to both limit over-fiting and improve performances\n",
    "ratios = [0.5, 1, 2, 3, 4, 5, 6, 8, 10]\n",
    "scoresf1 = [0] * len(ratios)\n",
    "i = 0\n",
    "for ratio in ratios:\n",
    "    scoref1 = [0] * 10\n",
    "    for j in range(10):\n",
    "        trainPos = sampleTrain[labels[sampleTrain] == 1]\n",
    "        trainNeg = sampleTrain[labels[sampleTrain] == 0]\n",
    "\n",
    "        dataNeg = np.random.choice(trainNeg, size= round(ratio * len(trainPos)), replace = False)\n",
    "        dataCV = data2V[np.concatenate((trainPos, dataNeg), 0)]\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(dataCV, labels[np.concatenate((trainPos, dataNeg), axis = 0)].astype(int))\n",
    "        # f1s = cross_val_score(clf, dataCV, labels[np.concatenate((trainPos, dataNeg), axis = 0)].astype(int), cv=5)\n",
    "        scoref1[j] =  predict_and_score(clf, data2V[sampleTest], labels[sampleTest].astype(int), silent = True)\n",
    "    scoresf1[i] = np.mean(scoref1)\n",
    "    i += 1\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"ratio between pnon-hateful and hateful tweets\")\n",
    "plt.ylabel(\"F1 scores on the test data\")\n",
    "plt.plot(ratios, scoresf1)\n",
    "plt.show();\n",
    "\n",
    "\n",
    "\n",
    "dataNeg = np.random.choice(trainNeg, size= round(3 * len(trainPos)), replace = False)\n",
    "newTrainBal = np.concatenate((trainPos, dataNeg), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "Train data\n",
      "0.8880335899230231\n",
      "[[4675   23]\n",
      " [ 297 1269]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      4698\n",
      "          1       0.98      0.81      0.89      1566\n",
      "\n",
      "avg / total       0.95      0.95      0.95      6264\n",
      "\n",
      "Test data\n",
      "0.6490842490842491\n",
      "[[8667  246]\n",
      " [ 233  443]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97      8913\n",
      "          1       0.64      0.66      0.65       676\n",
      "\n",
      "avg / total       0.95      0.95      0.95      9589\n",
      "\n",
      "Training new data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'File NB_stem_balanced_ratio3.csv saved.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrain the model with a new sampling: newTrainBal\n",
    "classifier2 = MultinomialNB()\n",
    "classifier2.fit(data2V[newTrainBal], labels[newTrainBal].astype(int))\n",
    "\n",
    "# check data integrity\n",
    "labelCount = wholeData['label'][newTrainBal].value_counts()\n",
    "balance = labelCount[0] / labelCount[1]\n",
    "print(balance)\n",
    "\n",
    "print('Train data')\n",
    "predict_and_score(classifier2, data2V[newTrainBal],  labels[newTrainBal])\n",
    "print('Test data')\n",
    "predict_and_score(classifier2, data2V[sampleTest], labels[sampleTest])\n",
    "\n",
    "print('Training new data')\n",
    "predict_and_save(classifier2, data2V[indexToTrain], \"NB_stem_balanced_ratio3.csv\", wholeData.iloc[indexToTrain,:]['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "0.9993610223642173\n",
      "[[1566    0]\n",
      " [   2 1564]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1566\n",
      "          1       1.00      1.00      1.00      1566\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3132\n",
      "\n",
      "Test data\n",
      "0.4696591853699086\n",
      "[[7748 1165]\n",
      " [ 111  565]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.87      0.92      8913\n",
      "          1       0.33      0.84      0.47       676\n",
      "\n",
      "avg / total       0.94      0.87      0.89      9589\n",
      "\n",
      "Training new data\n",
      "Train data\n",
      "0.9993610223642173\n",
      "[[4698    0]\n",
      " [   2 1564]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      4698\n",
      "          1       1.00      1.00      1.00      1566\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6264\n",
      "\n",
      "Test data\n",
      "0.6521443158611301\n",
      "[[8599  314]\n",
      " [ 197  479]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.96      0.97      8913\n",
      "          1       0.60      0.71      0.65       676\n",
      "\n",
      "avg / total       0.95      0.95      0.95      9589\n",
      "\n",
      "Training new data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'File RF100_stem_balanced_new_sample.csv saved.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use alternative algorithms on stemmed data\n",
    "classifier3 = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "classifier3.fit(data2V[sampleTrainBal], labels[sampleTrainBal].astype(int))\n",
    "\n",
    "print('Train data')\n",
    "predict_and_score(classifier3, data2V[sampleTrainBal],  labels[sampleTrainBal])\n",
    "print('Test data')\n",
    "predict_and_score(classifier3, data2V[sampleTest], labels[sampleTest])\n",
    "\n",
    "print('Training new data')\n",
    "predict_and_save(classifier3, data2V[indexToTrain], \"RF100_stem_balanced.csv\", wholeData.iloc[indexToTrain,:]['id'])\n",
    "\n",
    "classifier3 = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "classifier3.fit(data2V[newTrainBal], labels[newTrainBal].astype(int))\n",
    "\n",
    "print('Train data')\n",
    "predict_and_score(classifier3, data2V[newTrainBal],  labels[newTrainBal])\n",
    "print('Test data')\n",
    "predict_and_score(classifier3, data2V[sampleTest], labels[sampleTest])\n",
    "\n",
    "print('Training new data')\n",
    "predict_and_save(classifier3, data2V[indexToTrain], \"RF100_stem_balanced_new_sample.csv\", wholeData.iloc[indexToTrain,:]['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 0.3, 'n_estimators': 10}\n",
      "Train data\n",
      "0.4737845567206863\n",
      "[[4663   35]\n",
      " [1069  497]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.99      0.89      4698\n",
      "          1       0.93      0.32      0.47      1566\n",
      "\n",
      "avg / total       0.84      0.82      0.79      6264\n",
      "\n",
      "Test data\n",
      "0.41212121212121205\n",
      "[[8803  110]\n",
      " [ 472  204]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      8913\n",
      "          1       0.65      0.30      0.41       676\n",
      "\n",
      "avg / total       0.93      0.94      0.93      9589\n",
      "\n",
      "Training new data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'File RF_paramCV_stem_balanced.csv saved.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try to improve the RF hyperparameters to avoid overfitting\n",
    "classifier4 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [ 10, 20, 100, 200, 500],\n",
    "    'max_features': [0.3, 'auto', 'log2'],\n",
    "    'max_depth' :  [5, 6, 7, 8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "classifier4CV = GridSearchCV(estimator = classifier4, param_grid = param_grid, cv= 3)\n",
    "# {'criterion': 'gini', 'max_depth': 8, 'max_features': None, 'n_estimators': 200}\n",
    "classifier4CV.fit(data2V[newTrainBal], labels[newTrainBal].astype(int))\n",
    "print(classifier4CV.best_params_)\n",
    "\n",
    "print('Train data')\n",
    "predict_and_score(classifier4CV, data2V[newTrainBal],  labels[newTrainBal])\n",
    "print('Test data')\n",
    "predict_and_score(classifier4CV, data2V[sampleTest], labels[sampleTest])\n",
    "\n",
    "print('Training new data')\n",
    "predict_and_save(classifier4CV, data2V[indexToTrain], \"RF_paramCV_stem_balanced.csv\", wholeData.iloc[indexToTrain,:]['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# new approach based on lexicon\n",
    "data3 = wholeData.copy()\n",
    "# Lexicons\n",
    "\n",
    "# Emoticon lexicon\n",
    "# need the raw data to identify emoticons\n",
    "emoLexi = pd.read_csv('Data\\\\EmoticonSentimentLexicon.txt',\n",
    "                   sep = '\\t',\n",
    "                   header = 0)\n",
    "\n",
    "data3[\"emoScore\"] = 0\n",
    "data3[\"emoNb\"] = 0\n",
    "\n",
    "for emoIndex in range(0,emoLexi.shape[0]):\n",
    "    emo = emoLexi.iloc[emoIndex, 0]\n",
    "    data3[\"emoScore\"] = data3[\"emoScore\"] + data3[\"tweet\"].apply(lambda x: float(x.count(emo)) * float(emoLexi.iloc[emoIndex, 1]))\n",
    "    data3[\"emoNb\"] = data3[\"emoNb\"] + data3[\"tweet\"].apply(lambda x: x.count(emo))\n",
    "    \n",
    "plt.figure()\n",
    "plt.hist(data3[\"emoScore\"])\n",
    "plt.show()\n",
    "\n",
    "# Hastag lexicon\n",
    "lexicon = pd.read_csv('Data\\\\NRC-Hashtag-Emotion-Lexicon-v0.2.txt',\n",
    "                   sep = '\\t',\n",
    "                   header = 0,\n",
    "                     names = ['emotion', 'tag', 'score'])\n",
    "\n",
    "lexicon['tag'] = lexicon['tag'].apply(lambda x: re.sub('\\#', '', str(x)))  #removing hastag symbol allow more matches during the search, but also may lead ton aggregation during pivot\n",
    "\n",
    "# stemming to better generalisation\n",
    "# lexicon['tag'] = lexicon['tag'].apply(lambda x: st.stem(x))\n",
    "lex2 = lexicon.pivot_table(index = 'tag', columns = 'emotion', values = 'score') #default aggregation : numpy.mean, works here\n",
    "\n",
    "# Counting and stemming\n",
    "## Counting hastags and punctuation\n",
    "data3[\"exclamation\"] = data3[\"tweet\"].apply(lambda x: len(re.findall(\"!\", x)))\n",
    "data3[\"tags\"] = data3[\"tweet\"].apply(lambda x: len(re.findall(\"#\", x)))\n",
    "data3[\"len\"] = data3[\"tweet\"].apply(len)\n",
    "\n",
    "## removing @mentions and punctuation\n",
    "data3[\"tweet\"] = data3[\"tweet\"].apply(lambda x: re.sub(\"@[\\w]*|[^a-zA-Z ]+\", '', x))\n",
    "\n",
    "data4 = data3['tweet'][:].apply(lambda x: extractEmotion(x, lex2))\n",
    "data4 = pd.concat([data4, data3[[\"exclamation\",\"tags\",\"len\", \"emoScore\", \"emoNb\"]]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-fd6e4e2e81c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# plotting emotions in the different classes to see if some patterns emerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlabels2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m  \u001b[1;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'None'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata4\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"anger\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"anticipation\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"disgust\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fear\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"joy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sadness\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"surprise\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"trust\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels2' is not defined"
     ]
    }
   ],
   "source": [
    "# plotting emotions in the different classes to see if some patterns emerge\n",
    "labels2 = labels.copy()\n",
    "labels2 = [-1  if str(x) == 'None' else x for x in labels2]\n",
    "df =  pd.concat([data4[[\"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"trust\"]].fillna(0), pd.DataFrame(labels2, columns=[\"label\"])] , axis = 1)\n",
    "\n",
    "plt.figure()\n",
    "sns.pairplot(df.iloc[sampleTrainBal,:], vars= [\"anger\", \"disgust\",  \"joy\", \"trust\"],hue = \"label\", markers=\"+\",diag_kind=\"kde\")\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "1.0\n",
      "[[1566    0]\n",
      " [   0 1566]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1566\n",
      "          1       1.00      1.00      1.00      1566\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3132\n",
      "\n",
      "Test data\n",
      "0.29329090426942456\n",
      "[[6371 2542]\n",
      " [ 123  553]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.71      0.83      8913\n",
      "          1       0.18      0.82      0.29       676\n",
      "\n",
      "avg / total       0.92      0.72      0.79      9589\n",
      "\n",
      "Training new data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'File NB_emolexicon.csv saved.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(data4full)\n",
    "classifier6 = RandomForestClassifier(n_estimators = 100)\n",
    "#classifier6 = MultinomialNB()\n",
    "\n",
    "data44 = sparse.csr_matrix(np.nan_to_num(np.matrix(data4)))\n",
    "classifier6.fit(data44[sampleTrainBal], labels[sampleTrainBal].astype(int))\n",
    "    \n",
    "print('Train data')\n",
    "predict_and_score(classifier6, data44[sampleTrainBal],  labels[sampleTrainBal])\n",
    "print('Test data')\n",
    "predict_and_score(classifier6,data44[sampleTest], labels[sampleTest])\n",
    "\n",
    "print('Training new data')\n",
    "predict_and_save(classifier6, data44[indexToTrain], \"NB_emolexicon.csv\", wholeData.iloc[indexToTrain,:]['id'])\n",
    "# 0.342581423401689"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 2 round approach is designed to fight the 2 type error trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "1 classifier\n",
      "0.9980818414322251\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     20807\n",
      "          1       1.00      1.00      1.00      1566\n",
      "\n",
      "avg / total       1.00      1.00      1.00     22373\n",
      "\n",
      "[[20806     1]\n",
      " [    5  1561]]\n",
      "2 classifiers\n",
      "0.9980818414322251\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     20807\n",
      "          1       1.00      1.00      1.00      1566\n",
      "\n",
      "avg / total       1.00      1.00      1.00     22373\n",
      "\n",
      "[[20806     1]\n",
      " [    5  1561]]\n",
      "Test data\n",
      "1 classifier\n",
      "0.9985185185185186\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8913\n",
      "          1       1.00      1.00      1.00       676\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9589\n",
      "\n",
      "[[8913    0]\n",
      " [   2  674]]\n",
      "2 classifiers\n",
      "0.9985185185185186\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8913\n",
      "          1       1.00      1.00      1.00       676\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9589\n",
      "\n",
      "[[8913    0]\n",
      " [   2  674]]\n",
      "saving submission\n"
     ]
    }
   ],
   "source": [
    "# train model on word data:\n",
    "classifier21 = RandomForestClassifier(n_estimators = 100)\n",
    "classifier21.fit(data2V[indexTrain], labels[indexTrain].astype(int))\n",
    "prediction1 = classifier21.predict(data2V[sampleTrain])\n",
    "# selection of ambiguous terms:\n",
    "newTrain = sampleTrain[prediction1 == 0]\n",
    "# train a new model with lexicon data to deal with ambiguous data\n",
    "classifier22 = RandomForestClassifier(n_estimators = 100)\n",
    "# classifier22 = MultinomialNB()\n",
    "classifier22.fit(data2V[newTrain], labels[newTrain].astype(int))\n",
    "\n",
    "predAmbiTr = predict_ambiguous(classifier21, classifier22, data2V[sampleTrain], data2V[sampleTrain], 0)\n",
    "print(\"Train data\")\n",
    "print(\"1 classifier\")\n",
    "print(sklearn.metrics.f1_score(labels[sampleTrain].astype(int), classifier21.predict(data2V[sampleTrain])))\n",
    "print(sklearn.metrics.classification_report(labels[sampleTrain].astype(int), classifier21.predict(data2V[sampleTrain])))\n",
    "print(sklearn.metrics.confusion_matrix(labels[sampleTrain].astype(int), classifier21.predict(data2V[sampleTrain])))\n",
    "print(\"2 classifiers\")\n",
    "print(sklearn.metrics.f1_score(labels[sampleTrain].astype(int), predAmbiTr))\n",
    "print(sklearn.metrics.classification_report(labels[sampleTrain].astype(int), predAmbiTr))\n",
    "print(sklearn.metrics.confusion_matrix(labels[sampleTrain].astype(int), predAmbiTr))\n",
    "\n",
    "print(\"Test data\")\n",
    "predAmbi = predict_ambiguous(classifier21, classifier22, data2V[sampleTest], data2V[sampleTest], 0)\n",
    "print(\"1 classifier\")\n",
    "print(sklearn.metrics.f1_score(labels[sampleTest].astype(int), classifier21.predict(data2V[sampleTest])))\n",
    "print(sklearn.metrics.classification_report(labels[sampleTest].astype(int), classifier21.predict(data2V[sampleTest])))\n",
    "print(sklearn.metrics.confusion_matrix(labels[sampleTest].astype(int), classifier21.predict(data2V[sampleTest])))\n",
    "print(\"2 classifiers\")\n",
    "print(sklearn.metrics.f1_score(labels[sampleTest].astype(int), predAmbi))\n",
    "print(sklearn.metrics.classification_report(labels[sampleTest].astype(int), predAmbi))\n",
    "print(sklearn.metrics.confusion_matrix(labels[sampleTest].astype(int), predAmbi))\n",
    "\n",
    "print('saving submission')\n",
    "name = \"2_round_classification_RF_RF_indexTrain_and_full_train_sampling.csv\"\n",
    "ids =  wholeData.iloc[indexToTrain,:]['id']\n",
    "pred = predict_ambiguous(classifier21, classifier22, data2V[indexToTrain], data2V[indexToTrain], 0)\n",
    "df = pd.DataFrame({'id': ids, 'label': pred})\n",
    "df.to_csv(name, sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last solution is the best prediction that was made by the various methods tested. While many otehr approaches could be tested, this hybrid approach decomposing the problem provides a relatively good f1-score of 0.70. \n",
    "Please see the associated report for more discussion on the approach and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
