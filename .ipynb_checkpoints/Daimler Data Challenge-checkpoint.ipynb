{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up and data preparation\n",
    "\n",
    "### Package and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  label                                              tweet\n",
      "13        14      1  @user #cnn calls #michigan middle school 'buil...\n",
      "14        15      1  no comment!  in #australia   #opkillingbay #se...\n",
      "17        18      1                             retweet if you agree! \n",
      "23        24      1    @user @user lumpy says i am a . prove it lumpy.\n",
      "34        35      1  it's unbelievable that in the 21st century we'...\n",
      "56        57      1            @user lets fight against  #love #peace \n",
      "68        69      1  ð©the white establishment can't have blk fol...\n",
      "77        78      1  @user hey, white people: you can call people '...\n",
      "82        83      1  how the #altright uses  &amp; insecurity to lu...\n",
      "111      112      1  @user i'm not interested in a #linguistics tha...\n",
      "114      115      1  @user why not @user mocked obama for being bla...\n",
      "131      132      1  #people aren't protesting #trump because a #re...\n",
      "151      152      1  yes it's  when you call #michelleobama a goril...\n",
      "156      157      1  as the smaller hands show, barry probably lied...\n",
      "167      168      1  @user @user you point one finger @user million...\n",
      "192      193      1  you might be a libtard if... #libtard  #sjw #l...\n",
      "210      211      1  @user take out the #trash america...  - i vote...\n",
      "232      233      1  if you hold open a door for a woman because sh...\n",
      "263      264      1  @user this man ran for governor of ny, the sta...\n",
      "264      265      1  #stereotyping #prejudice  offer no #hope or so...\n",
      "269      270      1  how many#pols passed by how many times and sai...\n",
      "313      314      1    7 horribly  ads from #2016 that made us cringe \n",
      "321      322      1  @user \"the dying of the light\"  village green/...\n",
      "332      333      1  @user you never answered me about your stateme...\n",
      "354      355      1  you might be a libtard if... #libtard  #sjw #l...\n",
      "362      363      1  trump ny co-chair makes racist remarks about m...\n",
      "374      375      1  @user the pic says otherwise for young girls c...\n",
      "405      406      1  @user when you're blocked by a  troll because ...\n",
      "425      426      1  why the nazis studied american race laws for i...\n",
      "432      433      1  @user #biherism absolutely originated in hatef...\n",
      "...      ...    ...                                                ...\n",
      "31718  31719      1   white girl has sex with black guy girls nackt...\n",
      "31719  31720      1  are you #black &amp; feel like the  are stompi...\n",
      "31726  31727      1  @user @user @user @user the real  and #antisem...\n",
      "31739  31740      1  @user my video on the whole @user situation #b...\n",
      "31742  31743      1  @user you might be a libtard if... #libtard  #...\n",
      "31757  31758      1  @user stop these  chelski fans. #equality #div...\n",
      "31765  31766      1  what has todayÂs attitude to women got in com...\n",
      "31772  31773      1  #hatred,#greed&amp; destroyed many lives,but m...\n",
      "31777  31778      1    bringing back morals #obama  #dividerofanation \n",
      "31789  31790      1  #paladino is one of a rare breed of  that shou...\n",
      "31806  31807      1  please don't forget to use the word ! that is ...\n",
      "31817  31818      1  @user 'an unappetizing scam' :-) | women, we n...\n",
      "31829  31830      1  that hammock just attempted #whitegenocide #li...\n",
      "31863  31864      1  #us refuses to veto resolution on #israel  #zi...\n",
      "31864  31865      1  @user #allahsoil we should not conflate islami...\n",
      "31865  31866      1  see what #russia is doing in #syria,  destroyi...\n",
      "31882  31883      1  come on n wake the eff up usa! this is crazine...\n",
      "31891  31892      1  dr. frances cress welsing - racism defined #wh...\n",
      "31899  31900      1  @user the end of   #me #selfie # #love #messi ...\n",
      "31903  31904      1  @user @user  nothing. that would be .  #taharr...\n",
      "31912  31913      1  i couldn't end #2016 without mentioning #trump...\n",
      "31926  31927      1  a follow up from the gentlemen who were kicked...\n",
      "31929  31930      1  did  keep #colinpowell and #condoleezzarice fr...\n",
      "31930  31931      1  @user #feminismiscancer #feminismisterrorism #...\n",
      "31933  31934      1  @user judd is a  &amp; #homophobic #freemilo #...\n",
      "31934  31935      1  lady banned from kentucky mall. @user  #jcpenn...\n",
      "31946  31947      1  @user omfg i'm offended! i'm a  mailbox and i'...\n",
      "31947  31948      1  @user @user you don't have the balls to hashta...\n",
      "31948  31949      1   makes you ask yourself, who am i? then am i a...\n",
      "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
      "\n",
      "[2242 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Data\\\\train_E6oV3lV.csv',\n",
    "                   sep = ',',\n",
    "                   header = 0)\n",
    "\n",
    "totrain = pd.read_csv('Data\\\\test_tweets_anuFYb8.csv',\n",
    "                   sep = ',',\n",
    "                   header = 0)\n",
    "\n",
    "# Have a look on \n",
    "print(data[data['label'] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at data shape and integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelCount = data['label'].value_counts()\n",
    "labelCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No unlabelled value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.256021409455842"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance = labelCount[0] / labelCount[1]\n",
    "balance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of non-hate tweets is one order of magnitude larger than tweets labelled as hateful.\n",
    "This must be kept in mind if we use modelling methods that are sensitive to unbalanced design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### cleaning data\n",
    "import string, re\n",
    "\n",
    "#print(train[\"tweet\"].apply(str.strip))\n",
    "\n",
    "punctRE = re.compile(\"[a-zA-Z]+\" \" \")\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \"\".join(re.findall(punctRE, x)))\n",
    "#print(train)\n",
    "\n",
    "# Create train and test data sets\n",
    "import numpy as np\n",
    "sampleTrain =  np.random.rand(data.shape[0]) < 0.7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model\n",
    "\n",
    "First modelling attempt to have an idea of how complex the problem is. NaiveBayes is chosen because of its capacity to perform quite well in sentiment analysis and deal with a lot of features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "0.9613593624070923\n",
      "0.6614358571989015\n",
      "[[20628   109]\n",
      " [  754   843]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.98     20737\n",
      "          1       0.89      0.53      0.66      1597\n",
      "\n",
      "avg / total       0.96      0.96      0.96     22334\n",
      "\n",
      "Test data\n",
      "0.938616535105941\n",
      "0.4670874661857529\n",
      "[[8778  205]\n",
      " [ 386  259]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97      8983\n",
      "          1       0.56      0.40      0.47       645\n",
      "\n",
      "avg / total       0.93      0.94      0.93      9628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectoriser = CountVectorizer()\n",
    "dataTransformed = vectoriser.fit_transform(data[\"tweet\"].values)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "labels = data[\"label\"].values\n",
    "\n",
    "classifier.fit(dataTransformed[sampleTrain], labels[sampleTrain])\n",
    "\n",
    "\n",
    "print('Train data')\n",
    "predictionTr = classifier.predict(dataTransformed[sampleTrain])\n",
    "\n",
    "print(classifier.score(dataTransformed[sampleTrain], labels[sampleTrain]))\n",
    "\n",
    "print(sklearn.metrics.f1_score(labels[sampleTrain], predictionTr))\n",
    "print(sklearn.metrics.confusion_matrix(labels[sampleTrain], predictionTr))\n",
    "print(sklearn.metrics.classification_report(labels[sampleTrain], predictionTr))\n",
    "\n",
    "print('Test data')\n",
    "prediction = classifier.predict(dataTransformed[~sampleTrain])\n",
    "\n",
    "print(classifier.score(dataTransformed[~sampleTrain], labels[~sampleTrain]))\n",
    "\n",
    "print(sklearn.metrics.f1_score(labels[~sampleTrain], prediction))\n",
    "print(sklearn.metrics.confusion_matrix(labels[~sampleTrain], prediction))\n",
    "print(sklearn.metrics.classification_report(labels[~sampleTrain], prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The large difference in the precision of the detection of hateful tweets is a clear case of overfitting.\n",
    "The model show low recal of the hateful tweets for both train and test data. This is due to low performance in the elimination of false negative hateful tweets. It can be explained by the unbalanced design that gives more importance to the non-hateful tweets.\n",
    "\n",
    "Let's now try with a balanced design to improve the recall error of the hateful tweets.\n",
    "This is easily acheived by reducing the number of samples in the most numerous class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Train data\n",
      "0.806259514641354\n",
      "0.4180228648285138\n",
      "[[16453  4284]\n",
      " [   43  1554]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88     20737\n",
      "          1       0.27      0.97      0.42      1597\n",
      "\n",
      "avg / total       0.95      0.81      0.85     22334\n",
      "\n",
      "Test data\n",
      "0.7968065122103944\n",
      "0.41478809738503153\n",
      "[[2315  636]\n",
      " [  13  230]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.78      0.88      2951\n",
      "          1       0.27      0.95      0.41       243\n",
      "\n",
      "avg / total       0.94      0.80      0.84      3194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reduced = np.random.choice(data[\"id\"][(labels == 0) & (sampleTrain)], sum(labels[sampleTrain] == 1))-1\n",
    "sampleTrainB = np.append(reduced, data[\"id\"][(labels == 1) & (sampleTrain)] - 1)\n",
    "\n",
    "\n",
    "labelCount = data['label'][sampleTrainB].value_counts()\n",
    "print(labelCount[0] / labelCount[1])\n",
    "classifierB = MultinomialNB()\n",
    "\n",
    "classifierB.fit(dataTransformed[sampleTrainB], labels[sampleTrainB])\n",
    "\n",
    "print('Train data')\n",
    "predictionTrB = classifierB.predict(dataTransformed[sampleTrain])\n",
    "\n",
    "print(classifierB.score(dataTransformed[sampleTrain], labels[sampleTrain]))\n",
    "\n",
    "print(sklearn.metrics.f1_score(labels[sampleTrain], predictionTrB))\n",
    "print(sklearn.metrics.confusion_matrix(labels[sampleTrain], predictionTrB))\n",
    "print(sklearn.metrics.classification_report(labels[sampleTrain], predictionTrB))\n",
    "\n",
    "print('Test data')\n",
    "predictionB = classifierB.predict(dataTransformed[~sampleTrainB])\n",
    "\n",
    "print(classifierB.score(dataTransformed[~sampleTrainB], labels[~sampleTrainB]))\n",
    "\n",
    "print(sklearn.metrics.f1_score(labels[~sampleTrainB], predictionB))\n",
    "print(sklearn.metrics.confusion_matrix(labels[~sampleTrainB], predictionB))\n",
    "print(sklearn.metrics.classification_report(labels[~sampleTrainB], predictionB))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall is better because there is a great reduction of false negative for the hateful tweets, but the number of false positive greatly increases. There is a shift from high rate of false negatives to a high rate of false positives. \n",
    "\n",
    "The models is not able to correctly classify the non-hateful tweets that look like hateful tweets (false-positive hateful tweets, top-right cell of the confusion matrix).\n",
    "\n",
    "From there, multiple strategies can be adopted:\n",
    " \n",
    " * cleaning to reduce and potentially aggregate features and feature selection to reduce the number of selection. This should reduce the over fitting, however, it is unlikely that it will help with the difficult cases;\n",
    " * use random forests to reduce over fitting, and better distinguish ambiguous twwets (that look hateful but aren't necesseraly);\n",
    " * create new features, from the structure of the tweets (number of hastags, tweet length, punctuation, etc...) or use external resources such as lexicons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on existing feature, cleaning and selection\n",
    "\n",
    "### Cleaning text\n",
    "\n",
    "To avoid overfitting, non meaningful (in a human perspective) information such as mentions (@user) and urls can be discarded. The classification can also be improved by stemming the words, to regroup words by their common root, reducing the number of feature and building potentially stronger features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          father  dysfunctional    selfish  drags  kid...\n",
      "1        thanks  lyft credit  cant use cause  dont offe...\n",
      "2                                          bihday  majesty\n",
      "3                         model  love u take  u   time  ur\n",
      "4                           factsguide society  motivation\n",
      "5        huge fan fare  big talking   leave chaos  pay ...\n",
      "6                                   camping tomorrow danny\n",
      "7         next school year   year  exams cant think   s...\n",
      "8          love  land allin cavs champions cleveland cl...\n",
      "9                                         welcome  im   gr\n",
      "10       ireland consumer price index mom climbed  prev...\n",
      "11          selfish orlando standwithorlando pulseshoot...\n",
      "12                   get  see  daddy today days gettingfed\n",
      "13       cnn calls michigan middle school build  wall c...\n",
      "14        comment  australia opkillingbay seashepherd h...\n",
      "15                 ouchjunior  angrygot junior yugyoem omg\n",
      "16                     thankful    paner thankful positive\n",
      "17                                         retweet   agree\n",
      "18        friday smiles  around via ig user cookies mak...\n",
      "19                   know essential oils   made  chemicals\n",
      "20       euro people blaming ha  conceded goal   fat ro...\n",
      "21       sad little dude badday coneofshame cats pissed...\n",
      "22       product   day happy man wine tool whos   weeke...\n",
      "23                              lumpy says    prove  lumpy\n",
      "24           tgif ff   gamedev indiedev indiegamedev squad\n",
      "25       beautiful sign  vendor  upsideofflorida shopal...\n",
      "26        smiles  media  pressconference  antalya turke...\n",
      "27          great panel   mediatization   public servic...\n",
      "28                                       happy fathers day\n",
      "29       people went  nightclub    good night  mans act...\n",
      "                               ...                        \n",
      "31932                                         thanks gemma\n",
      "31933    judd   amp homophobic freemilo milo freemilo m...\n",
      "31934          lady banned  kentucky mall jcpenny kentucky\n",
      "31935    ugh im trying  enjoy  happy hour drink amp   t...\n",
      "31936    want  know   live  life   things  make  happy ...\n",
      "31937                                          love island\n",
      "31938     fav actor vijaysethupathi  fav actress   fav ...\n",
      "31939                            whew   productive  friday\n",
      "31940                                        shes finally \n",
      "31941    passed first year  uni yay love pass unistuden...\n",
      "31942            week  flying  humpday wednesday kamp ucsd\n",
      "31943    modeling photoshoot  friday yay model  follow emo\n",
      "31944    youre surrounded  people  love  even    deserv...\n",
      "31945               feel like dog summer hot help sun day \n",
      "31946    omfg im offended im  mailbox  im proud mailbox...\n",
      "31947     dont   balls  hashtag      say    weasel away...\n",
      "31948         makes  ask        anybody  god oh thank  god\n",
      "31949    hear one   new songs dont go katie ellie youtu...\n",
      "31950      try  tail us  stop butt     good   time gold...\n",
      "31951         ive  posted  new blog secondlife lonely neko\n",
      "31952                                           went  far \n",
      "31953    good morning instagram shower water berlin ber...\n",
      "31954    holiday bull    dominate  bull    direct  what...\n",
      "31955     less  weeks ibizabringitonmallorcaholidayssummer\n",
      "31956        fishing tomorrow carnt wait first time  years\n",
      "31957                                       ate isz  youuu\n",
      "31958     see nina turner   airwaves trying  wrap    ma...\n",
      "31959    listening  sad songs   monday morning otw  wor...\n",
      "31960    sikh temple vandalised   calgary wso condemns act\n",
      "31961                                      thank    follow\n",
      "Name: tweet, Length: 31962, dtype: object\n"
     ]
    }
   ],
   "source": [
    "##### cleaning data\n",
    "import string, re\n",
    "\n",
    "data0 = pd.read_csv('Data\\\\train_E6oV3lV.csv',\n",
    "                   sep = ',',\n",
    "                   header = 0)\n",
    "data = data0.copy()\n",
    "\n",
    "## removing @mentions and punctuation\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda x: re.sub(\"@[\\w]*|[^a-zA-Z ]+\", '', x))\n",
    "\n",
    "## stemming\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "st = LancasterStemmer()\n",
    "import nltk\n",
    "# nltk.download('punkt') # if needed\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tokenize import  word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# stem sentnce function\n",
    "def cleanSentence(s, stops):\n",
    "    words = []\n",
    "    for w in word_tokenize(s):\n",
    "        # words.append(st.stem(w))\n",
    "         words.append(w * (w not in stops))\n",
    "    return(\" \".join(words))\n",
    "\n",
    "#print(data[\"tweet\"])\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda x: cleanSentence(x, stop_words))\n",
    "##/!\\ stemming might be a bit long\n",
    "\n",
    "print(data[\"tweet\"])\n",
    "# cleaning stop words:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "0.9744171560775938\n",
      "0.7924936845904005\n",
      "[[20803   103]\n",
      " [  472  1098]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99     20906\n",
      "          1       0.91      0.70      0.79      1570\n",
      "\n",
      "avg / total       0.97      0.97      0.97     22476\n",
      "\n",
      "Test data\n",
      "0.9438119333755007\n",
      "0.5909439754412894\n",
      "[[8568  246]\n",
      " [ 287  385]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97      8814\n",
      "          1       0.61      0.57      0.59       672\n",
      "\n",
      "avg / total       0.94      0.94      0.94      9486\n",
      "\n",
      "With balanced sample:\n",
      "1.0\n",
      "Train data\n",
      "0.8708844990211781\n",
      "0.5114478114478115\n",
      "[[18055  2851]\n",
      " [   51  1519]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.93     20906\n",
      "          1       0.35      0.97      0.51      1570\n",
      "\n",
      "avg / total       0.95      0.87      0.90     22476\n",
      "\n",
      "Test data\n",
      "0.8719745222929937\n",
      "0.5191387559808612\n",
      "[[2521  389]\n",
      " [  13  217]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.87      0.93      2910\n",
      "          1       0.36      0.94      0.52       230\n",
      "\n",
      "avg / total       0.95      0.87      0.90      3140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create train and test data sets\n",
    "import numpy as np\n",
    "sampleTrain =  np.random.rand(data.shape[0]) < 0.7\n",
    "\n",
    "# Vectorise features\n",
    "vectoriser = CountVectorizer()\n",
    "dataTransformed = vectoriser.fit_transform(data[\"tweet\"].values)\n",
    "\n",
    "#build and fit classifier\n",
    "classifier = MultinomialNB()\n",
    "labels = data[\"label\"].values\n",
    "\n",
    "classifier.fit(dataTransformed[sampleTrain], labels[sampleTrain])\n",
    "\n",
    "\n",
    "print('Train data')\n",
    "predictionTr = classifier.predict(dataTransformed[sampleTrain])\n",
    "\n",
    "print(classifier.score(dataTransformed[sampleTrain], labels[sampleTrain]))\n",
    "\n",
    "print(sklearn.metrics.f1_score(labels[sampleTrain], predictionTr))\n",
    "print(sklearn.metrics.confusion_matrix(labels[sampleTrain], predictionTr))\n",
    "print(sklearn.metrics.classification_report(labels[sampleTrain], predictionTr))\n",
    "\n",
    "print('Test data')\n",
    "prediction = classifier.predict(dataTransformed[~sampleTrain])\n",
    "\n",
    "print(classifier.score(dataTransformed[~sampleTrain], labels[~sampleTrain]))\n",
    "\n",
    "print(sklearn.metrics.f1_score(labels[~sampleTrain], prediction))\n",
    "print(sklearn.metrics.confusion_matrix(labels[~sampleTrain], prediction))\n",
    "print(sklearn.metrics.classification_report(labels[~sampleTrain], prediction))\n",
    "\n",
    "print('With balanced sample:')\n",
    "reduced = np.random.choice(data[\"id\"][(labels == 0) & (sampleTrain)], sum(labels[sampleTrain] == 1))-1\n",
    "sampleTrainB = np.append(reduced, data[\"id\"][(labels == 1) & (sampleTrain)] - 1)\n",
    "\n",
    "\n",
    "labelCount = data['label'][sampleTrainB].value_counts()\n",
    "print(labelCount[0] / labelCount[1])\n",
    "classifierB = MultinomialNB()\n",
    "\n",
    "classifierB.fit(dataTransformed[sampleTrainB], labels[sampleTrainB])\n",
    "\n",
    "print('Train data')\n",
    "predictionTrB = classifierB.predict(dataTransformed[sampleTrain])\n",
    "\n",
    "print(classifierB.score(dataTransformed[sampleTrain], labels[sampleTrain]))\n",
    "\n",
    "print(sklearn.metrics.f1_score(labels[sampleTrain], predictionTrB))\n",
    "print(sklearn.metrics.confusion_matrix(labels[sampleTrain], predictionTrB))\n",
    "print(sklearn.metrics.classification_report(labels[sampleTrain], predictionTrB))\n",
    "\n",
    "print('Test data')\n",
    "predictionB = classifierB.predict(dataTransformed[~sampleTrainB])\n",
    "\n",
    "print(classifierB.score(dataTransformed[~sampleTrainB], labels[~sampleTrainB]))\n",
    "\n",
    "print(sklearn.metrics.f1_score(labels[~sampleTrainB], predictionB))\n",
    "print(sklearn.metrics.confusion_matrix(labels[~sampleTrainB], predictionB))\n",
    "print(sklearn.metrics.classification_report(labels[~sampleTrainB], predictionB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the stemming steps makes the whole procedure much longer, it does improve the performances in balanced and umbalanced sampling. There is still some overfitting with the larger umbalanced train dataset.\n",
    "\n",
    "Feature selection with CV procedure should reduce the over fitting. However, it is not likely that it will solve the low accuracy of the classification of ambiguous tweets. Random forest (RF) may help, otherwise, more complex approaches will be considered.\n",
    "The benefit of the sampling is yet to be tested, but it may show with RF.\n",
    "\n",
    "### Cross validation and reverse feature selection\n",
    "\n",
    "Because text analysis rely on numerous features (words)forward selection is prefered to backward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 39615\n",
      "39615\n",
      "[0.         0.05406107 0.12000118 0.18905983 0.21643666 0.25876549\n",
      " 0.28179609 0.29965713 0.32650364 0.34785193 0.37308409 0.40075825\n",
      " 0.40570002 0.42226087 0.4322689  0.44419721 0.45152958 0.45298259\n",
      " 0.45898946 0.46572097 0.46909335 0.47269005 0.48067056 0.48467389\n",
      " 0.48054898 0.48331767 0.48563545 0.4861009  0.48539168 0.48483641\n",
      " 0.48618527 0.48703442 0.48968178 0.49436941 0.4947599  0.49491321\n",
      " 0.49475026 0.55579227 0.59050902 0.6554166  0.85098854]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "0.9710191082802547\n",
      "0.9709172259507829\n",
      "Test data\n",
      "0.8719745222929937\n",
      "0.5191387559808612\n",
      "[[2521  389]\n",
      " [  13  217]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.87      0.93      2910\n",
      "          1       0.36      0.94      0.52       230\n",
      "\n",
      "avg / total       0.95      0.87      0.90      3140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "nsteps = 1000\n",
    "rfecv = RFECV(estimator=classifier, step=nsteps, cv= 3,\n",
    "              scoring='f1')\n",
    "rfecv.fit(dataTransformed[sampleTrainB], labels[sampleTrainB])\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "print(len(rfecv.support_))\n",
    "print(str(rfecv.grid_scores_))\n",
    "#print(len())\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, nsteps *len(rfecv.grid_scores_) + 1, nsteps), rfecv.grid_scores_)\n",
    "plt.show()\n",
    "\n",
    "print(\"Train data\")\n",
    "predictionCVtrain = rfecv.estimator_.predict(dataTransformed[sampleTrainB])\n",
    "print(rfecv.estimator_.score(dataTransformed[sampleTrainB], labels[sampleTrainB]))\n",
    "print(sklearn.metrics.f1_score(labels[sampleTrainB], predictionCVtrain))\n",
    "\n",
    "print(\"Test data\")\n",
    "predictionCV = rfecv.estimator_.predict(dataTransformed[~sampleTrainB])\n",
    "print(rfecv.estimator_.score(dataTransformed[~sampleTrainB], labels[~sampleTrainB]))\n",
    "print(sklearn.metrics.f1_score(labels[~sampleTrainB], predictionCV))\n",
    "print(sklearn.metrics.confusion_matrix(labels[~sampleTrainB], predictionCV))\n",
    "print(sklearn.metrics.classification_report(labels[~sampleTrainB], predictionCV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature selection does not greatly improve the accuracy. However, the balanced sampling allows better performances than the unbalanced sampling (not shown) for models with a number of features under 30,000. This encourages us to continue with the balanced sample.\n",
    "\n",
    "There is still a large over-fitting, despite the CV procedure, therefore, alternative model should be tested.\n",
    "\n",
    "### Random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "0.8821695760598504\n",
      "0.544891640866873\n",
      "[[18226  2631]\n",
      " [   15  1584]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.87      0.93     20857\n",
      "          1       0.38      0.99      0.54      1599\n",
      "\n",
      "avg / total       0.95      0.88      0.90     22456\n",
      "\n",
      "Test data\n",
      "0.8771106941838649\n",
      "0.5282112845138055\n",
      "[[2585  379]\n",
      " [  14  220]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.87      0.93      2964\n",
      "          1       0.37      0.94      0.53       234\n",
      "\n",
      "avg / total       0.95      0.88      0.90      3198\n",
      "\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifierRF = RandomForestClassifier(n_estimators = 10)\n",
    "classifierRF.fit(dataTransformed[sampleTrainB], labels[sampleTrainB])\n",
    "\n",
    "print('Train data')\n",
    "predictionTrFR = classifierRF.predict(dataTransformed[sampleTrain])\n",
    "\n",
    "print(classifierRF.score(dataTransformed[sampleTrain], labels[sampleTrain]))\n",
    "\n",
    "print(sklearn.metrics.f1_score(labels[sampleTrain], predictionTrFR))\n",
    "print(sklearn.metrics.confusion_matrix(labels[sampleTrain], predictionTrFR))\n",
    "print(sklearn.metrics.classification_report(labels[sampleTrain], predictionTrFR))\n",
    "\n",
    "print('Test data')\n",
    "predictionFR = classifierRF.predict(dataTransformed[~sampleTrainB])\n",
    "\n",
    "print(classifierRF.score(dataTransformed[~sampleTrainB], labels[~sampleTrainB]))\n",
    "\n",
    "print(sklearn.metrics.f1_score(labels[~sampleTrainB], predictionFR))\n",
    "print(sklearn.metrics.confusion_matrix(labels[~sampleTrainB], predictionFR))\n",
    "print(sklearn.metrics.classification_report(labels[~sampleTrainB], predictionFR))\n",
    "\n",
    "####Cross validation on the number of trees\n",
    "f1_scores = [0] * len(range(64,128, 4))\n",
    "rep = 5\n",
    "i = 0\n",
    "for nt in range(64,128, 4):\n",
    "    f1_score = [0] * rep\n",
    "    j = 0\n",
    "    for nr in range(1,rep):\n",
    "        sampleTrain =  np.random.rand(data.shape[0]) < 0.7\n",
    "        reduced = np.random.choice(data[\"id\"][(labels == 0) & (sampleTrain)], sum(labels[sampleTrain] == 1))-1\n",
    "        sampleTrainB = np.append(reduced, data[\"id\"][(labels == 1) & (sampleTrain)] - 1)\n",
    "        classifierRF = RandomForestClassifier(n_estimators = nt)\n",
    "        classifierRF.fit(dataTransformed[sampleTrainB], labels[sampleTrainB])\n",
    "        predictionFR = classifierRF.predict(dataTransformed[~sampleTrainB])\n",
    "        f1_score[j] = sklearn.metrics.f1_score(labels[~sampleTrainB], predictionFR)\n",
    "        j += 1\n",
    "    f1_scores[i] = np.mean(f1_score)\n",
    "    i += 1\n",
    "    print(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46120176413345887, 0.45086337809531846, 0.46446567546663486, 0.461119504080253, 0.44424117631428367, 0.4736141827718434, 0.44203899099554117, 0.4516394800040402, 0.4553525340961291, 0.45203983283185334, 0.4452633701702025, 0.45496735644328756, 0.4684898032862096, 0.44704029522433614, 0.4493431776824609, 0.4596098889152869]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f1_scores)\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"F1 scores on the test data\")\n",
    "plt.plot(range(64,128, 4), f1_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the random forest eliminates the over-fitting, the accuracy seems to be only marginally improved by solely playing with the parameters of this method.\n",
    "\n",
    "\n",
    "### Feature selection with mutual information criterion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "0.8096430807764559\n",
      "0.8136112814224402\n",
      "[[1259  338]\n",
      " [ 270 1327]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.79      0.81      1597\n",
      "          1       0.80      0.83      0.81      1597\n",
      "\n",
      "avg / total       0.81      0.81      0.81      3194\n",
      "\n",
      "Test data\n",
      "0.49843456480901693\n",
      "0.3591549295774648\n",
      "[[2262  689]\n",
      " [  39  204]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.77      0.86      2951\n",
      "          1       0.23      0.84      0.36       243\n",
      "\n",
      "avg / total       0.93      0.77      0.82      3194\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'tocsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-c18933afa518>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0msampleTrainB\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[1;34m\"test_file.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                ~sampleTrainB)\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;31m# prediction = classifier.predict(dataTransformed[~sampleTrainB, :][:,selector.get_support(indices=True)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-161-c18933afa518>\u001b[0m in \u001b[0;36mpredictAndScore\u001b[1;34m(cls, data, lbs, name, ids)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"File {0} saved.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4370\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4371\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4372\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4374\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'tocsv'"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "#Create selector, and apply:\n",
    "selector = SelectKBest(mutual_info_classif, k=200)\n",
    "data_red = selector.fit_transform(dataTransformed[sampleTrainB], labels[sampleTrainB])\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "\n",
    "classifier.fit(data_red, labels[sampleTrainB])\n",
    "\n",
    "def predictAndScore(cls, data, lbs, name = None, ids = None):\n",
    "    pred = cls.predict(data)\n",
    "\n",
    "    print(cls.score(data, labels[sampleTrainB]))\n",
    "    \n",
    "    f1_score = sklearn.metrics.f1_score(lbs, pred)\n",
    "    print(sklearn.metrics.f1_score(lbs, pred))\n",
    "    print(sklearn.metrics.confusion_matrix(lbs, pred))\n",
    "    print(sklearn.metrics.classification_report(lbs, pred))\n",
    "    \n",
    "    if name:\n",
    "        df = pd.DataFrame({'id': ids, 'label': pred})\n",
    "        df.to_csv(name, sep = ',')\n",
    "        print(\"File {0} saved.\".format(name))\n",
    "    return f1_score\n",
    "\n",
    "print('Train data')\n",
    "predictAndScore(classifier, data_red,  labels[sampleTrainB])\n",
    "# predictionTr = classifier.predict(data_red)\n",
    "\n",
    "# print(classifier.score(data_red, labels[sampleTrainB]))\n",
    "\n",
    "# print(sklearn.metrics.f1_score(labels[sampleTrainB], predictionTr))\n",
    "# print(sklearn.metrics.confusion_matrix(labels[sampleTrainB], predictionTr))\n",
    "# print(sklearn.metrics.classification_report(labels[sampleTrainB], predictionTr))\n",
    "\n",
    "print('Test data')\n",
    "predictAndScore(classifier, dataTransformed[~sampleTrainB, :][:,selector.get_support(indices=True)],\n",
    "                labels[~sampleTrainB],\n",
    "                \"test_file.csv\",\n",
    "               ~sampleTrainB)\n",
    "# prediction = classifier.predict(dataTransformed[~sampleTrainB, :][:,selector.get_support(indices=True)])\n",
    "\n",
    "# print(classifier.score(dataTransformed[~sampleTrainB, :][:,selector.get_support(indices=True)], labels[~sampleTrainB]))\n",
    "\n",
    "# print(sklearn.metrics.f1_score(labels[~sampleTrainB], prediction))\n",
    "# print(sklearn.metrics.confusion_matrix(labels[~sampleTrainB], prediction))\n",
    "# print(sklearn.metrics.classification_report(labels[~sampleTrainB], prediction))\n",
    "\n",
    "# try to train the test dataset given\n",
    "# dataToTrain = vectoriser.fit_transform(totrain['tweet'])\n",
    "# dataToTrain2 = dataToTrain.iloc[:,selector.get_support(indices=True)]\n",
    "# print(dataToTrain2.shape)\n",
    "# trained['id'] = totrain['id']\n",
    "# trained['label'] = classifier.predict(dataToTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-78a1beaeb331>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mpipe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mutual_info'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'naive_bayes'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataTransformed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             return_times=True)\n\u001b[1;32m--> 206\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \"\"\"\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[0;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                     **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    214\u001b[0m                 \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                        **fit_params):\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[0mscore_func_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\mutual_info_.py\u001b[0m in \u001b[0;36mmutual_info_classif\u001b[1;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m     return _estimate_mi(X, y, discrete_features, True, n_neighbors,\n\u001b[1;32m--> 450\u001b[1;33m                         copy, random_state)\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\mutual_info_.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[1;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[1;32m--> 289\u001b[1;33m           x, discrete_feature in moves.zip(_iterate_columns(X), discrete_mask)]\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\mutual_info_.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[1;32m--> 289\u001b[1;33m           x, discrete_feature in moves.zip(_iterate_columns(X), discrete_mask)]\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\mutual_info_.py\u001b[0m in \u001b[0;36m_compute_mi\u001b[1;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \"\"\"\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx_discrete\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my_discrete\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmutual_info_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mx_discrete\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0my_discrete\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py\u001b[0m in \u001b[0;36mmutual_info_score\u001b[1;34m(labels_true, labels_pred, contingency)\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontingency\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[0mlabels_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_clusterings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[0mcontingency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontingency_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m         contingency = check_array(contingency,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py\u001b[0m in \u001b[0;36mcontingency_matrix\u001b[1;34m(labels_true, labels_pred, eps, sparse)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot set 'eps' when sparse=True\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[0mclusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcluster_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid axis kwarg specified for unique'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moptional_indices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mperm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mergesort'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_index\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'quicksort'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline        \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "selector = SelectKBest(mutual_info_classif, k=200)\n",
    "#data_red = selector.fit_transform(dataTransformed, labels)\n",
    "#print(selector)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "pipe = Pipeline([('mutual_info',selector), ('naive_bayes',clf)])\n",
    "\n",
    "scores = cross_val_score(pipe, dataTransformed, labels, cv =10, scoring = 'accuracy')\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  126   234   452   514   837   933  1000  1003  1051  1091  1112  1158\n",
      "  1245  1489  1495  2144  2965  3297  3534  3536  3553  3763  3802  3819\n",
      "  3884  3929  3940  4275  4375  4546  4900  5177  5189  5482  5488  6268\n",
      "  6275  6637  6667  6841  6908  7080  8035  8391  8433  9315  9322 10620\n",
      " 10923 11235 11513 11559 11603 11647 11701 11703 11770 11771 11901 11999\n",
      " 12000 12001 12002 12245 12747 12998 13041 13195 13221 14157 15137 15152\n",
      " 15285 15313 15456 15833 15843 16042 16528 16696 16701 17022 17623 17763\n",
      " 17777 17791 17792 18125 18197 19020 19463 19577 19670 19869 19886 19906\n",
      " 20003 20142 20559 21052 21229 21907 22079 22099 22101 22149 22179 22354\n",
      " 22358 22526 22786 23193 23510 23574 23575 23960 23977 24103 24517 24740\n",
      " 24746 25318 25682 25683 25690 26394 26934 26944 26945 26973 27123 27422\n",
      " 27628 27741 28009 28010 28185 28208 28214 28216 28394 28524 28792 28967\n",
      " 29141 29147 29256 30331 30337 30556 30579 30776 30916 30926 31067 31126\n",
      " 31438 31461 31629 31887 32372 33035 33064 33451 33507 33520 33662 33866\n",
      " 33944 34078 34213 34253 34310 34425 34575 34870 35201 35360 35454 35473\n",
      " 35702 35811 35984 36007 36794 36906 37856 37863 38110 38225 38252 38257\n",
      " 38262 38271 38614 38625 38674 38935 39021 39561]\n"
     ]
    }
   ],
   "source": [
    "#print(type(selector.fit(dataTransformed, labels)))\n",
    "\n",
    "print(selector.get_support(indices=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative approaches: new features extraction\n",
    "\n",
    "### Structural feature extractions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10847256116638508\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data0 = pd.read_csv('Data\\\\train_E6oV3lV.csv',\n",
    "                   sep = ',',\n",
    "                   header = 0)\n",
    "\n",
    "data2 = data0.copy()\n",
    "# Lexicons\n",
    "\n",
    "# Emoticon lexicon\n",
    "# need the raw data to identify emoticons\n",
    "emoLexi = pd.read_csv('Data\\\\EmoticonSentimentLexicon.txt',\n",
    "                   sep = '\\t',\n",
    "                   header = 0)\n",
    "\n",
    "data2[\"emoScore\"] = 0\n",
    "data2[\"emoNb\"] = 0\n",
    "# emoLexi.iloc[:,0] = emoLexi.iloc[:,0].str.replace('\\(', '\\\\(')\n",
    "# emoLexi.iloc[:,0] = emoLexi.iloc[:,0].str.replace('\\)', '\\\\)')\n",
    "# emoLexi.iloc[:,0] = emoLexi.iloc[:,0].str.replace('\\*', '\\\\*')\n",
    "# emoLexi.iloc[:,0] = emoLexi.iloc[:,0].str.replace('\\+', '\\\\+')\n",
    "\n",
    "for emoIndex in range(0,emoLexi.shape[0]):\n",
    "    emo = emoLexi.iloc[emoIndex, 0]\n",
    "    data2[\"emoScore\"] = data2[\"emoScore\"] + data2[\"tweet\"].apply(lambda x: float(x.count(emo)) * float(emoLexi.iloc[emoIndex, 1]))\n",
    "    data2[\"emoNb\"] = data2[\"emoNb\"] + data2[\"tweet\"].apply(lambda x: x.count(emo))\n",
    "    \n",
    "print(np.mean(data2['emoNb']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.0000e+00, 2.0000e+00, 3.8000e+01, 2.6100e+02, 0.0000e+00,\n",
       "        2.8935e+04, 2.4750e+03, 2.2200e+02, 2.4000e+01, 4.0000e+00]),\n",
       " array([-4. , -3.2, -2.4, -1.6, -0.8,  0. ,  0.8,  1.6,  2.4,  3.2,  4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(data2[\"emoScore\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is no surprise that only a fraction of tweets contain emoticon that are in the lexicon, but this information maystill be usefull to classify tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion     anger  anticipation   disgust      fear       joy   sadness  \\\n",
      "0        0.368288      0.448039  0.585179  0.696964  0.307466  0.114774   \n",
      "1        0.313450      0.305425  0.497088  0.183055  0.087149  0.300441   \n",
      "2        0.036483           NaN  0.455425       NaN       NaN       NaN   \n",
      "3        0.071944      0.170763  0.653715  0.290777  0.641363  0.723940   \n",
      "4        0.069792      0.213096  0.862856  0.016300  0.994770       NaN   \n",
      "5        0.368987      0.075789  0.670443  0.369098  0.682899  0.068925   \n",
      "6             NaN      0.345652       NaN  0.709802  0.679367  0.368198   \n",
      "7        0.273956      0.201011  0.541674  0.413752  0.457824  0.061785   \n",
      "8        0.301275      0.394754  0.412066  0.291494  0.580655  0.232387   \n",
      "9        0.250447           NaN  0.181909  0.125311  0.283869  0.117751   \n",
      "10       0.537612      0.470297  0.300371  0.074521  0.121384  0.154122   \n",
      "11       0.256340      0.260004  0.589363  0.234023  0.561461  0.124603   \n",
      "12       0.115118      0.193658  0.620664  0.191361  0.286629  0.199855   \n",
      "13       0.426634      0.558255  0.577556  0.380356  0.910417  0.009564   \n",
      "14       0.223634      0.452991  0.441736  0.096518       NaN  0.170903   \n",
      "15       0.002799      0.393038  0.043997  0.457667       NaN       NaN   \n",
      "16       0.104509      0.547356  1.145632  0.214083  1.467157       NaN   \n",
      "17       0.246558           NaN  0.659211       NaN       NaN  0.031050   \n",
      "18       0.251991      0.178620  0.516677  0.392738  1.066996  0.120851   \n",
      "19       0.459992      0.357987  0.609054  0.394150  0.777501  0.024296   \n",
      "20       0.215872      0.340064  0.634797  0.289804  1.061914  0.184870   \n",
      "21       0.652656      0.441259  0.267190       NaN  0.408253  0.954781   \n",
      "22       0.296214      0.302160  0.367143  0.302733  0.974687  0.429536   \n",
      "23       0.118097      0.620467  1.177012  0.056755       NaN       NaN   \n",
      "24       0.189429      0.560737  0.673697  0.103185  0.781989  0.495588   \n",
      "25            NaN      0.144853  1.256100  0.371412  1.074827       NaN   \n",
      "26       0.186484      0.363431  0.602057  0.399999  0.977188  0.452920   \n",
      "27       0.243187      0.385915  0.638113  0.493328  0.874964  0.024296   \n",
      "28            NaN           NaN  0.462708       NaN  1.224551  0.726296   \n",
      "29       0.260069           NaN  0.415129  0.266383  0.424158  0.433601   \n",
      "...           ...           ...       ...       ...       ...       ...   \n",
      "31932    0.146682           NaN  0.312200       NaN  0.087149       NaN   \n",
      "31933    0.170948      0.379339  0.981901       NaN       NaN       NaN   \n",
      "31934    0.186722      0.603348  0.454776  0.323422       NaN       NaN   \n",
      "31935    0.133514      0.356982  0.449785  0.268924  0.781003  0.110247   \n",
      "31936    0.279669      2.105551  0.408820  0.389819  0.916946  0.343959   \n",
      "31937         NaN      0.312187       NaN  0.095656  0.746585       NaN   \n",
      "31938    0.181403      0.446432  0.916544  0.407791  0.416190  0.243284   \n",
      "31939    0.464097      0.199204       NaN  0.661520  0.798844  0.159159   \n",
      "31940    0.138237      0.172852  0.294463  0.125311  1.176420  0.010592   \n",
      "31941         NaN      0.166344       NaN  0.401521  0.758420  0.115274   \n",
      "31942    0.002799      0.266210  1.231691  0.609555  0.256975       NaN   \n",
      "31943    0.244756      0.155360  0.600392  0.577554  0.631156  0.757781   \n",
      "31944    0.216595      1.528593  0.618244  0.173882  0.612486  0.245766   \n",
      "31945    0.118072      1.354593  0.272124  0.361962  0.675707  0.474113   \n",
      "31946    0.268659      0.668862  0.318021  0.565659  0.746451  0.357364   \n",
      "31947    0.288833      0.739612  0.493040  0.249967  0.115229  0.164339   \n",
      "31948    0.224590      0.467376  0.658912  0.291215  0.652991  0.185593   \n",
      "31949    0.203662      0.322615  0.513832  0.287807  0.615536  0.102910   \n",
      "31950    0.224473      0.207345  0.415835  0.553050  0.546034  0.337575   \n",
      "31951         NaN      0.631973  0.412178  0.780435  0.588979  0.933849   \n",
      "31952    0.074628           NaN  0.506919       NaN  0.435666  0.106862   \n",
      "31953    0.293040      0.158037  0.325530  0.565659  0.685204  0.627782   \n",
      "31954    0.293521      0.196848  0.706512  0.081494  1.286915  0.276114   \n",
      "31955         NaN      1.221695       NaN  0.917858  0.073804       NaN   \n",
      "31956    0.466916      0.380995  0.595617  0.407750  0.373003  0.424341   \n",
      "31957    0.079989           NaN  0.579921       NaN       NaN       NaN   \n",
      "31958    0.196450      0.351298  0.644478  0.326910  0.374043  0.103928   \n",
      "31959    0.018235      0.340358  0.416699  0.235404  0.411228  0.757968   \n",
      "31960    0.362474           NaN  0.404803  0.488584       NaN  0.031326   \n",
      "31961    0.073887      0.061206  0.602199  0.371412  0.555973  0.261327   \n",
      "\n",
      "emotion  surprise     trust  \n",
      "0        0.067065  0.859600  \n",
      "1        0.042500  1.196628  \n",
      "2             NaN  1.130983  \n",
      "3        0.075671  0.558460  \n",
      "4        0.453622  0.656771  \n",
      "5        0.295639  1.129859  \n",
      "6        0.431092       NaN  \n",
      "7        0.205695  0.924422  \n",
      "8        0.151513  0.380964  \n",
      "9             NaN  1.464276  \n",
      "10       0.228235  0.536252  \n",
      "11       0.112011  0.435831  \n",
      "12       0.238379  0.797403  \n",
      "13       0.130657  0.435850  \n",
      "14            NaN  0.739326  \n",
      "15       0.129664  0.412189  \n",
      "16       0.132373  0.956092  \n",
      "17            NaN  0.733234  \n",
      "18       0.340904  0.718779  \n",
      "19       0.259927  0.151293  \n",
      "20       0.300380  0.674591  \n",
      "21       0.166648  0.437836  \n",
      "22       0.012617  0.801031  \n",
      "23            NaN  1.088057  \n",
      "24       0.072403  0.569581  \n",
      "25       0.279210  0.648199  \n",
      "26       0.268103  0.773377  \n",
      "27       0.181456  0.808491  \n",
      "28            NaN       NaN  \n",
      "29       0.253167  0.835627  \n",
      "...           ...       ...  \n",
      "31932    0.075655       NaN  \n",
      "31933    0.072049  1.285906  \n",
      "31934    0.310915       NaN  \n",
      "31935    0.283791  0.773149  \n",
      "31936    0.192651  0.923043  \n",
      "31937    0.049481  0.720369  \n",
      "31938    0.349209  0.998308  \n",
      "31939    0.587557  1.476999  \n",
      "31940    0.053148       NaN  \n",
      "31941    0.427855  0.720369  \n",
      "31942    0.135319  0.943256  \n",
      "31943    0.349200  1.044781  \n",
      "31944    0.104845  0.653540  \n",
      "31945    0.315441  1.725857  \n",
      "31946    0.587707  1.146363  \n",
      "31947    0.424380  1.057696  \n",
      "31948    0.114923  0.729262  \n",
      "31949    0.457661  0.932522  \n",
      "31950    0.203865  0.777538  \n",
      "31951    0.128216  1.705571  \n",
      "31952    0.395205  0.507878  \n",
      "31953    0.184092  0.652246  \n",
      "31954    0.058726  0.786392  \n",
      "31955    0.025421       NaN  \n",
      "31956    0.195046  0.797388  \n",
      "31957         NaN  0.984379  \n",
      "31958    0.397184  1.267129  \n",
      "31959    0.306438  0.850522  \n",
      "31960    0.480294  1.030899  \n",
      "31961    0.110408  1.028130  \n",
      "\n",
      "[31962 rows x 8 columns]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-e03004190092>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m#Concatenate the lexicon data with the punctuation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m \u001b[0mdata3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"exclamation\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"tags\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"len\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataTransformed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;31m### This step is quite demanding in RAM, but it is necessary to fit the model in a reasonnable time and avoid memory problems\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    945\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from scipy import sparse\n",
    "\n",
    "st = LancasterStemmer()\n",
    "import nltk\n",
    "#nltk.download('punkt') # if needed\n",
    "from nltk.tokenize import  word_tokenize\n",
    "\n",
    "# Hastag lexicon\n",
    "lexicon = pd.read_csv('Data\\\\NRC-Hashtag-Emotion-Lexicon-v0.2.txt',\n",
    "                   sep = '\\t',\n",
    "                   header = 0,\n",
    "                     names = ['emotion', 'tag', 'score'])\n",
    "\n",
    "lexicon['tag'] = lexicon['tag'].apply(lambda x: re.sub('\\#', '', str(x)))  #removing hastag symbol allow more matches during the search, but also may lead ton aggregation during pivot\n",
    "#lexicon['tag'] = lexicon['tag'].apply(lambda x: type(x))  #removing hastag symbol allow more matches during the search, but also may lead ton aggregation during pivot\n",
    "\n",
    "# stemming to better generalisation\n",
    "# lexicon['tag'] = lexicon['tag'].apply(lambda x: st.stem(x))\n",
    "lex2 = lexicon.pivot_table(index = 'tag', columns = 'emotion', values = 'score') #default aggregation : numpy.mean, works here\n",
    "\n",
    "# Counting and stemming\n",
    "## Counting hastags and punctuation\n",
    "data2[\"exclamation\"] = data2[\"tweet\"].apply(lambda x: len(re.findall(\"!\", x)))\n",
    "data2[\"tags\"] = data2[\"tweet\"].apply(lambda x: len(re.findall(\"#\", x)))\n",
    "data2[\"len\"] = data2[\"tweet\"].apply(len)\n",
    "\n",
    "## removing @mentions and punctuation\n",
    "data2[\"tweet\"] = data2[\"tweet\"].apply(lambda x: re.sub(\"@[\\w]*|[^a-zA-Z ]+\", '', x))\n",
    "\n",
    "## stemming\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "st = LancasterStemmer()\n",
    "import nltk\n",
    "#nltk.download('punkt') # if needed\n",
    "from nltk.tokenize import  word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extractEmotion(s, lex):\n",
    "    inter = set(s.split()).intersection(lex.index)\n",
    "    #print(inter)\n",
    "    #print(lex.loc[inter, :])\n",
    "    return lex.loc[inter, :].mean(axis = 0)\n",
    "\n",
    "data3 = data2['tweet'][:].apply(lambda x: extractEmotion(x, lex2))\n",
    "print(data3)\n",
    "\n",
    "\n",
    "# stem sentnce function\n",
    "def stemSentence(s):\n",
    "    words = []\n",
    "    for w in word_tokenize(s):\n",
    "        words.append(st.stem(w))\n",
    "    return(\" \".join(words))\n",
    "\n",
    "\n",
    "# data2[\"tweet\"] = data2[\"tweet\"].apply(lambda x: stemSentence(x))\n",
    "\n",
    "# print(data2)\n",
    "\n",
    "dataTransformed = vectoriser.fit_transform(data2[\"tweet\"].values)\n",
    "\n",
    "    #Concatenate the lexicon data with the punctuation data\n",
    "data3 = pd.concat([data3, data2[[\"exclamation\",\"tags\",\"len\"]], pd.DataFrame(dataTransformed.toarray())], axis = 1)\n",
    "\n",
    "### This step is quite demanding in RAM, but it is necessary to fit the model in a reasonnable time and avoid memory problems\n",
    "data3 = sparse.csr_matrix(np.nan_to_num(np.matrix(data3)))  \n",
    "print(\"data merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31962, 8)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[20991  4800  9139 ... 31933 31934 31948] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-42553ed60f32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclassifier_lex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclassifier_lex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msampleTrainB\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msampleTrainB\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2678\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2679\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2680\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2721\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2722\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2723\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[20991  4800  9139 ... 31933 31934 31948] not in index'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(data3.shape)\n",
    "classifier_lex = MultinomialNB()\n",
    "classifier_lex.fit(data3[sampleTrainB], labels[sampleTrainB])\n",
    "\n",
    "print('Train data')\n",
    "predictionT_lex = classifier_lex.predict(data3[sampleTrain])\n",
    "\n",
    "print(classifier_lex.score(data3[sampleTrain], labels[sampleTrain]))\n",
    "\n",
    "print(sklearn.metrics.f1_score(labels[sampleTrain], predictionT_lex))\n",
    "print(sklearn.metrics.confusion_matrix(labels[sampleTrain], predictionT_lex))\n",
    "print(sklearn.metrics.classification_report(labels[sampleTrain], predictionT_lex))\n",
    "\n",
    "print('Test data')\n",
    "prediction_lex = classifier_lex.predict(data3[~sampleTrainB])\n",
    "\n",
    "print(classifier_lex.score(data3[~sampleTrainB], labels[~sampleTrainB]))\n",
    "\n",
    "print(sklearn.metrics.f1_score(labels[~sampleTrainB], prediction_lex))\n",
    "print(sklearn.metrics.confusion_matrix(labels[~sampleTrainB], prediction_lex))\n",
    "print(sklearn.metrics.classification_report(labels[~sampleTrainB], prediction_lex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These new features does not help the classifier, they even decrease the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Counting hastags and punctuation\n",
    "data2[\"exclamation\"] = data2[\"tweet\"].apply(lambda x: len(re.findall(\"!\", x)))\n",
    "data2[\"tags\"] = data2[\"tweet\"].apply(lambda x: len(re.findall(\"#\", x)))\n",
    "data2[\"len\"] = data2[\"tweet\"].apply(len)\n",
    "\n",
    "## removing @mentions and punctuation\n",
    "data2[\"tweet\"] = data2[\"tweet\"].apply(lambda x: re.sub(\"@[\\w]*|[^a-zA-Z ]+\", '', x))\n",
    "\n",
    "## stemming\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "st = LancasterStemmer()\n",
    "import nltk\n",
    "#nltk.download('punkt') # if needed\n",
    "from nltk.tokenize import  word_tokenize\n",
    "\n",
    "\n",
    "# stem sentnce function\n",
    "def stemSentence(s):\n",
    "    words = []\n",
    "    for w in word_tokenize(s):\n",
    "        words.append(st.stem(w))\n",
    "    return(\" \".join(words))\n",
    "\n",
    "data2[\"tweet\"] = data2[\"tweet\"].apply(lambda x: stemSentence(x))\n",
    "\n",
    "# print(data2)\n",
    "\n",
    "dataTransformed = vectoriser.fit_transform(data2[\"tweet\"].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "0.7971331606680361\n",
      "0.39740018570102137\n",
      "[[16353  4486]\n",
      " [   57  1498]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.88     20839\n",
      "          1       0.25      0.96      0.40      1555\n",
      "\n",
      "avg / total       0.94      0.80      0.84     22394\n",
      "\n",
      "Test data\n",
      "0.8008338678640154\n",
      "0.39414634146341465\n",
      "[[2295  614]\n",
      " [   7  202]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88      2909\n",
      "          1       0.25      0.97      0.39       209\n",
      "\n",
      "avg / total       0.95      0.80      0.85      3118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "dataTransformed =  csr_matrix(np.hstack((dataTransformed.A, data2.iloc[:,-3:].values)))\n",
    "\n",
    "classifierB = MultinomialNB()\n",
    "\n",
    "classifierB.fit(dataTransformed[sampleTrainB], labels[sampleTrainB])\n",
    "\n",
    "print('Train data')\n",
    "predictionTrB = classifierB.predict(dataTransformed[sampleTrain])\n",
    "\n",
    "print(classifierB.score(dataTransformed[sampleTrain], labels[sampleTrain]))\n",
    "\n",
    "print(sklearn.metrics.f1_score(labels[sampleTrain], predictionTrB))\n",
    "print(sklearn.metrics.confusion_matrix(labels[sampleTrain], predictionTrB))\n",
    "print(sklearn.metrics.classification_report(labels[sampleTrain], predictionTrB))\n",
    "\n",
    "print('Test data')\n",
    "predictionB = classifierB.predict(dataTransformed[~sampleTrainB])\n",
    "\n",
    "print(classifierB.score(dataTransformed[~sampleTrainB], labels[~sampleTrainB]))\n",
    "\n",
    "print(sklearn.metrics.f1_score(labels[~sampleTrainB], predictionB))\n",
    "print(sklearn.metrics.confusion_matrix(labels[~sampleTrainB], predictionB))\n",
    "print(sklearn.metrics.classification_report(labels[~sampleTrainB], predictionB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hat'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"hate\"\n",
    "st.stem(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it has the potential to reduce and aggregate the stemming, stemming may also aggregate feature with opposite effect on the prediction. (i.e. `hate` being stemmed to `hat`). It probably necessary to spend more time constructing feature that makes sense in the context of the langauge, such as the identification of suffixes (i.e. *phobia*) and other language features that carry strong meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined approach\n",
    "\n",
    "Naive Bayes models perform relatively well, and are able to classify a large portion of the dataset, it fails to classify certain tweets. One strategy could be to try to identify these tweet (with a second model) and focus on these. This is the approach developped in the following part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start from the first dataset:\n",
    "sampleTrain =  np.random.rand(data.shape[0]) < 0.7\n",
    "# balance the sampling\n",
    "reduced = np.random.choice(data[\"id\"][(labels == 0) & (sampleTrain)], sum(labels[sampleTrain] == 1))-1\n",
    "sampleTrainB = np.append(reduced, data[\"id\"][(labels == 1) & (sampleTrain)] - 1)\n",
    "\n",
    "# and retransform the data (just in case)\n",
    "dataTransformed = vectoriser.fit_transform(data[\"tweet\"].values)\n",
    "\n",
    "#define a first classifier\n",
    "classifierB = MultinomialNB()\n",
    "labels = data[\"label\"].values\n",
    "\n",
    "classifierB.fit(dataTransformed[sampleTrainB], labels[sampleTrainB])\n",
    "\n",
    "predictionTrB = classifierB.predict(dataTransformed[sampleTrainB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 0 0 0]\n",
      "6037\n",
      "(31962,)\n",
      "[ 8654 28257  4882 ... 31947 31948 31960]\n",
      "Train\n",
      "0.9482758620689655\n",
      "0.9494949494949495\n",
      "[[134  11]\n",
      " [  4 141]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.92      0.95       145\n",
      "          1       0.93      0.97      0.95       145\n",
      "\n",
      "avg / total       0.95      0.95      0.95       290\n",
      "\n",
      "Test\n",
      "0.5172413793103449\n",
      "0.42148760330578516\n",
      "[[ 99 134]\n",
      " [  6  51]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.42      0.59       233\n",
      "          1       0.28      0.89      0.42        57\n",
      "\n",
      "avg / total       0.81      0.52      0.55       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The new stuff arrives here \n",
    "\n",
    "# error detection\n",
    "predictionTrB = classifierB.predict(dataTransformed)\n",
    "error = (predictionTrB - labels) ** 2\n",
    "balanced =  [False] * error.shape[0]\n",
    "for i in sampleTrainB:\n",
    "    balanced[i] = True\n",
    "reduced = np.random.choice(data[\"id\"][(error == 0) & (balanced)], sum(error[balanced] == 1))-1\n",
    "sampleTrainE = np.append(reduced, data[\"id\"][(error == 1) & (balanced)] - 1)\n",
    "\n",
    "classifierError = MultinomialNB()\n",
    "classifierError.fit(dataTransformed[sampleTrainE], error[sampleTrainE])\n",
    "\n",
    "print('Error detection model')\n",
    "print('Train')\n",
    "predictionError = classifierError.predict(dataTransformed[sampleTrainE])\n",
    "print(classifierError.score(dataTransformed[sampleTrainE], error[sampleTrainE]))\n",
    "print(sklearn.metrics.f1_score(error[sampleTrainE], predictionError))\n",
    "print(sklearn.metrics.confusion_matrix(error[sampleTrainE], predictionError))\n",
    "print(sklearn.metrics.classification_report(error[sampleTrainE], predictionError))\n",
    "\n",
    "print('Test')\n",
    "predictionError = classifierError.predict(dataTransformed[~sampleTrainE])\n",
    "print(classifierError.score(dataTransformed[~sampleTrainE], error[~sampleTrainE]))\n",
    "print(sklearn.metrics.f1_score(error[~sampleTrainE], predictionError))\n",
    "print(sklearn.metrics.confusion_matrix(error[~sampleTrainE], predictionError))\n",
    "print(sklearn.metrics.classification_report(error[~sampleTrainE], predictionError))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low ability of the model to detect potentially ambiguous tweet does not encourage to continue in that direction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69248292 0.72933182 0.68720379]\n",
      "Test data\n",
      "0.9073248407643312\n",
      "0.4849557522123894\n",
      "[[2712  198]\n",
      " [  93  137]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.93      0.95      2910\n",
      "          1       0.41      0.60      0.48       230\n",
      "\n",
      "avg / total       0.93      0.91      0.92      3140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Boosting method may work better\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(\n",
    "    n_estimators=100)\n",
    "scores = cross_val_score(clf, dataTransformed[sampleTrainB], labels[sampleTrainB], scoring= \"f1\")\n",
    "print(scores)\n",
    "clf.fit( dataTransformed[sampleTrainB], labels[sampleTrainB], )\n",
    "\n",
    "print('Test data')\n",
    "predictionB = clf.predict(dataTransformed[~sampleTrainB])\n",
    "\n",
    "print(clf.score(dataTransformed[~sampleTrainB], labels[~sampleTrainB]))\n",
    "\n",
    "print(sklearn.metrics.f1_score(labels[~sampleTrainB], predictionB))\n",
    "print(sklearn.metrics.confusion_matrix(labels[~sampleTrainB], predictionB))\n",
    "print(sklearn.metrics.classification_report(labels[~sampleTrainB], predictionB))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
